{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR4bovYL4CJz"
   },
   "source": [
    "## COMP5623M Assessment Coursework 1 - Image Classification [100 marks]\n",
    "\n",
    "The maximum number of marks for each part are shown in the section headers. As indicated in the main heading above, the overall assessment carries a maximum of 100 marks.\n",
    "\n",
    "This summative assessment is weighted 25% of the final grade for the module.\n",
    "\n",
    "### Motivation \n",
    "\n",
    "Through this coursework, you will:\n",
    "\n",
    "> 1. Practice building, evaluating, and finetuning a convolutional neural network on an image dataset from development to testing. \n",
    "> 2. Gain a deeper understanding of feature maps and filters by visualizing some from a pre-trained network. \n",
    "\n",
    "\n",
    "### Setup and resources \n",
    "\n",
    "You must work using this provided template notebook.\n",
    "\n",
    "Having a GPU will speed up the training process, especially for Question 1.3. See the provided document on Minerva about setting up a working environment for various ways to access a GPU.\n",
    "\n",
    "Please implement the coursework using **Python and PyTorch**, and refer to the notebooks and exercises provided.\n",
    "\n",
    "This coursework will use a subset of images from Tiny ImageNet, which is a subset of the ImageNet dataset [https://image-net.org/]. Our subset of Tiny ImageNet contains 30 different categories, we will refer to it as TinyImageNet30. The training set has 450 resized images (64x64 pixels) for each category (13,500 images in total). You can download the training and test set from the Kaggle website:\n",
    "\n",
    ">[Private class Kaggle competition and data](https://www.kaggle.com/t/9b703e0d71824a658e186d5f69960e27)\n",
    "\n",
    "To access the dataset, you will need an account on the Kaggle website. Even if you have an existing Kaggle account, please carefully adhere to these instructions, or we may not be able to locate your entries:\n",
    "\n",
    "> 1. Use your **university email** to register a new account.\n",
    "> 2. Set your **Kaggle account NAME** to your university username, for example, ``sc15jb``.\n",
    "\n",
    "The class Kaggle competition also includes a blind test set, which will be used in Question 1 for evaluating your custom model's performance on a test set. The competition website will compute the test set accuracy, as well as position your model on the class leaderboard.\n",
    "\n",
    "### Submission\n",
    "\n",
    "Please submit the following:\n",
    "\n",
    "> 1. Your completed Jupyter notebook file, without removing anything in the template, in **.ipynb format.**\n",
    "> 2. The **.html version** of your notebook; File > Download as > HTML (.html). Check that all cells have been run and all outputs (including all graphs you would like to be marked) displayed in the .html for marking.\n",
    "> 3. Your selected image from section 2.4.2 \"Failure analysis\"\n",
    "\n",
    "Final note:\n",
    "\n",
    "> **Please display everything that you would like to be marked. Under each section, put the relevant code containing your solution. You may re-use functions you defined previously, but any new code must be in the relevant section.** Feel free to add as many code cells as you need under each section.\n",
    "\n",
    "Your student username (for example, ```sc15jb```):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0axnvxOTQjP_"
   },
   "source": [
    "sc21kj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zii-dVPeQjQA"
   },
   "source": [
    "Your full name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12lnEYvwQjQB"
   },
   "source": [
    "Kalyan Jothimurugan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "morH0MECQjQB"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Feel free to add to this section as needed.\n",
    "\n",
    "You may need to download `cv2` using [pip](https://pypi.org/project/opencv-python/) or [conda](https://anaconda.org/conda-forge/opencv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "36LaR1KLQjQC"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "root=\"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notify():\n",
    "    os.system(\"printf '\\7'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfR--uYXHdIi"
   },
   "source": [
    "## QUESTION 1 [55 marks]\n",
    "\n",
    "One challenge of building a deep learning model is to choose an architecture that can learn the features in the dataset without being unnecessarily complex. The first part of the coursework involves building a CNN and training it on TinyImageNet30. \n",
    "\n",
    "### **Overview:**\n",
    "*   **1.1.1** PyTorch ```Dataset``` and ```DataLoader``` classes\n",
    "*   **1.1.2** PyTorch ```Model``` class for simple CNN model\n",
    "*   **1.1.3** Overfitting on a single batch\n",
    "*   **1.2.1** Training on complete dataset\n",
    "*   **1.2.2** Fine-tuning model\n",
    "*   **1.2.3** Generating confusion matrices\n",
    "*   **1.3**   Testing on test set on Kaggle\n",
    "\n",
    "\n",
    "## 1.1 Single-batch training [14 marks]\n",
    "\n",
    "We will use a method of development called “single-batch training”, or \"overfitting a single batch\", in which we check that our model and the training code is working properly and can overfit a single training batch (i.e., we can drive the training loss to zero). Then we move on to training on the complete training set and adjust for any overfitting and fine-tune the model via regularisation.\n",
    "\n",
    "### 1.1.1 Dataset class [3 marks]\n",
    "\n",
    "Write a PyTorch ```Dataset``` class (an example [here](https://www.askpython.com/python-modules/pytorch-custom-datasets) for reference) which loads the TinyImage30 dataset and ```DataLoaders``` for training and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baboon', 'banana', 'bee', 'bison', 'butterfly', 'candle', 'cardigan', 'chihuahua', 'elephant', 'espresso', 'fly', 'goldfish', 'goose', 'grasshopper', 'hourglass', 'icecream', 'ipod', 'jellyfish', 'koala', 'ladybug', 'lion', 'mushroom', 'penguin', 'pig', 'pizza', 'pretzel', 'redpanda', 'refrigerator', 'sombrero', 'umbrella']\n"
     ]
    }
   ],
   "source": [
    "class TinyImageNet(Dataset):\n",
    "    def __init__(self, result_directory, transform):\n",
    "        self.result_directory = result_directory\n",
    "        self.transform = transform\n",
    "        every_imgs = os.listdir(result_directory)\n",
    "        self.each_images = natsorted(every_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.each_images)\n",
    "    \n",
    "    def __getitem__(self, xyz):\n",
    "        location = os.path.join(self.result_directory, self.each_images[xyz])\n",
    "        image = Image.open(location).convert(\"RGB\")\n",
    "        tensorimage = self.transform(image)\n",
    "        return self.each_images[xyz] ,torch.unsqueeze(tensorimage, 0)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  #numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], #(x-mean)/std\n",
    "                        [0.5,0.5,0.5])])\n",
    "\n",
    "# Loading datasets\n",
    "dataset = ImageFolder(root+'/train_set/train_set',transform=transform)\n",
    "classes = dataset.classes\n",
    "print((dataset.classes))\n",
    "training_size = int(0.7 * len(dataset))\n",
    "validation_size = len(dataset) - training_size\n",
    "training_dataset, validation_dataset = torch.utils.data.random_split(dataset, [training_size, validation_size])\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset,batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=15, shuffle=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "\n",
    "        self.main_dir =main_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return self.total_imgs[idx] ,torch.unsqueeze(tensor_image, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJLU_x3EQjQG"
   },
   "source": [
    "### 1.1.2 Define a CNN model [3 marks]\n",
    "\n",
    "Create a new model class using a combination of convolutional and fully connected layers, ReLU, and max-pool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ep-wGwKQjQG",
    "outputId": "d8c46266-11f9-4174-acd5-d7e7f3981347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 3, 3])\n",
      "torch.Size([8])\n",
      "torch.Size([16, 8, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([128, 2048])\n",
      "torch.Size([128])\n",
      "torch.Size([30, 128])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=8, kernel_size=3,padding=1),   \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=8,out_channels=16,  kernel_size=3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=16,out_channels=32,  kernel_size=3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32*8*8,128),     \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,30)\n",
    ")\n",
    "\n",
    "cnn_v1 = net.to(device)\n",
    "\n",
    "for param in cnn_v1.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZROG9CCQjQG"
   },
   "source": [
    "### 1.1.3 Single-batch training [8 marks]\n",
    "\n",
    "Write the foundational code which trains your cnn_v1work given **one single batch** of training data and computes the loss on the complete validation set for each epoch. Set ```batch_size = 64```. \n",
    "\n",
    "Display the graph of the training and validation loss over training epochs, showing as long as necessary to show you can drive the training loss to zero.\n",
    "\n",
    "> Please leave all graphs and code you would like to be marked clearly displayed without needing to run code cells or wait for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "k8RhE-_mQjQH"
   },
   "outputs": [],
   "source": [
    "def stats(loader, cnn_v1):\n",
    "    crct = 0\n",
    "    total = 0\n",
    "    runningloss = 0\n",
    "    n = 0   \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            image_s, label_s = data\n",
    "            images, labels = image_s.to(device), label_s.to(device)\n",
    "            out_puts = cnn_v1(images)      \n",
    "            runningloss += lossfunction(out_puts, labels)\n",
    "            n += 1\n",
    "            _, predicted = torch.max(out_puts.data, 1)\n",
    "            total += labels.size(0)   \n",
    "            crct += (predicted == labels).sum().item()  \n",
    "            \n",
    "    return runningloss/n, crct/total \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ewtBO0CQQjQH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                          | 1/200 [00:02<09:21,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                          | 2/200 [00:05<08:19,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                          | 3/200 [00:07<07:57,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                          | 4/200 [00:09<07:46,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█                                          | 5/200 [00:12<07:39,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                         | 6/200 [00:14<07:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                         | 7/200 [00:16<07:29,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 training loss:  3.398 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                         | 8/200 [00:18<07:26,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 training loss:  3.397 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▉                                         | 9/200 [00:21<07:23,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 training loss:  3.397 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                        | 10/200 [00:23<07:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 training loss:  3.397 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                       | 11/200 [00:25<07:17,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 training loss:  3.397 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                       | 12/200 [00:28<07:15,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 training loss:  3.396 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▋                                       | 13/200 [00:30<07:12,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 training loss:  3.396 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▉                                       | 14/200 [00:32<07:10,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 training loss:  3.396 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                      | 15/200 [00:35<07:08,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 training loss:  3.395 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▎                                      | 16/200 [00:37<07:05,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 training loss:  3.395 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▌                                      | 17/200 [00:39<07:03,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 training loss:  3.395 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▊                                      | 18/200 [00:42<07:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 training loss:  3.394 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                      | 19/200 [00:44<06:59,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 training loss:  3.394 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▏                                     | 20/200 [00:46<06:56,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 training loss:  3.393 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                     | 21/200 [00:49<06:54,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 training loss:  3.393 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▌                                     | 22/200 [00:51<06:52,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 training loss:  3.393 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▊                                     | 23/200 [00:53<06:50,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 training loss:  3.392 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████                                     | 24/200 [00:56<06:47,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 training loss:  3.392 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████▎                                    | 25/200 [00:58<06:46,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 training loss:  3.392 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▍                                    | 26/200 [01:00<06:43,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 training loss:  3.391 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▋                                    | 27/200 [01:02<06:41,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 training loss:  3.391 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▉                                    | 28/200 [01:05<06:38,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 training loss:  3.390 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████                                    | 29/200 [01:07<06:36,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 training loss:  3.390 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▎                                   | 30/200 [01:09<06:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 training loss:  3.390 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▌                                   | 31/200 [01:12<06:32,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 training loss:  3.389 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▋                                   | 32/200 [01:14<06:29,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 training loss:  3.389 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▉                                   | 33/200 [01:16<06:28,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 training loss:  3.388 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                  | 34/200 [01:19<06:25,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 training loss:  3.388 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▎                                  | 35/200 [01:21<06:22,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 training loss:  3.387 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▌                                  | 36/200 [01:23<06:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 training loss:  3.387 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▊                                  | 37/200 [01:26<06:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 training loss:  3.387 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████▉                                  | 38/200 [01:28<06:15,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 training loss:  3.386 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▏                                 | 39/200 [01:30<06:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 training loss:  3.386 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 40/200 [01:33<06:11,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 training loss:  3.385 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▌                                 | 41/200 [01:35<06:08,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 training loss:  3.385 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████▊                                 | 42/200 [01:37<06:06,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 training loss:  3.385 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████                                 | 43/200 [01:40<06:03,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 training loss:  3.384 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▏                                | 44/200 [01:42<06:01,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 training loss:  3.384 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▍                                | 45/200 [01:44<05:59,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 training loss:  3.383 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▋                                | 46/200 [01:47<05:57,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 training loss:  3.383 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████▊                                | 47/200 [01:49<05:55,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 training loss:  3.383 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████                                | 48/200 [01:51<05:52,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 training loss:  3.382 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████▎                               | 49/200 [01:54<05:50,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 training loss:  3.382 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████▌                               | 50/200 [01:56<05:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 training loss:  3.381 training accuracy:  4.7%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████▋                               | 51/200 [01:58<05:45,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 training loss:  3.381 training accuracy:  6.2%  test loss:  3.402 test accuracy:  3.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████▉                               | 52/200 [02:01<05:43,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 training loss:  3.380 training accuracy:  6.2%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████▏                              | 53/200 [02:03<05:41,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 training loss:  3.380 training accuracy:  7.8%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████▎                              | 54/200 [02:05<05:38,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 training loss:  3.380 training accuracy:  7.8%  test loss:  3.402 test accuracy:  3.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████▌                              | 55/200 [02:08<05:40,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 training loss:  3.379 training accuracy:  9.4%  test loss:  3.402 test accuracy:  3.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████▊                              | 56/200 [02:10<05:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 training loss:  3.379 training accuracy:  9.4%  test loss:  3.402 test accuracy:  3.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████▉                              | 57/200 [02:12<05:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 training loss:  3.378 training accuracy:  10.9%  test loss:  3.402 test accuracy:  3.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████▏                             | 58/200 [02:15<05:31,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 training loss:  3.378 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▍                             | 59/200 [02:17<05:28,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 training loss:  3.377 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▌                             | 60/200 [02:19<05:26,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 training loss:  3.377 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▊                             | 61/200 [02:22<05:23,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 training loss:  3.377 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████                             | 62/200 [02:24<05:21,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 training loss:  3.376 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████▏                            | 63/200 [02:26<05:18,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 training loss:  3.376 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████▍                            | 64/200 [02:29<05:16,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 training loss:  3.375 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████▋                            | 65/200 [02:31<05:14,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 training loss:  3.375 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████▊                            | 66/200 [02:33<05:11,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 training loss:  3.374 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████                            | 67/200 [02:35<05:09,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 training loss:  3.374 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████▎                           | 68/200 [02:38<05:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 training loss:  3.373 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████▍                           | 69/200 [02:40<05:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 training loss:  3.373 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████▋                           | 70/200 [02:43<05:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 training loss:  3.373 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████▉                           | 71/200 [02:45<05:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 training loss:  3.372 training accuracy:  14.1%  test loss:  3.402 test accuracy:  3.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████                           | 72/200 [02:47<05:02,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 training loss:  3.372 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████▎                          | 73/200 [02:50<05:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 training loss:  3.371 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████▌                          | 74/200 [02:52<04:58,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 training loss:  3.371 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████▊                          | 75/200 [02:54<04:55,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 training loss:  3.370 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████▉                          | 76/200 [02:57<04:51,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 training loss:  3.370 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████▏                         | 77/200 [02:59<04:48,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 training loss:  3.369 training accuracy:  12.5%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|████████████████▍                         | 78/200 [03:01<04:47,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 training loss:  3.369 training accuracy:  10.9%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▌                         | 79/200 [03:04<04:52,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 training loss:  3.368 training accuracy:  10.9%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▊                         | 80/200 [03:06<04:50,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 training loss:  3.368 training accuracy:  10.9%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████                         | 81/200 [03:09<04:46,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 training loss:  3.367 training accuracy:  10.9%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████▏                        | 82/200 [03:11<04:41,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 training loss:  3.367 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████▍                        | 83/200 [03:13<04:36,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 training loss:  3.366 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████▋                        | 84/200 [03:16<04:33,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 training loss:  3.366 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████▊                        | 85/200 [03:18<04:30,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 training loss:  3.365 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████                        | 86/200 [03:20<04:27,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 training loss:  3.365 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████▎                       | 87/200 [03:23<04:24,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 training loss:  3.364 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████▍                       | 88/200 [03:25<04:22,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 training loss:  3.364 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████▋                       | 89/200 [03:27<04:19,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 training loss:  3.363 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████▉                       | 90/200 [03:30<04:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 training loss:  3.363 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████                       | 91/200 [03:32<04:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 training loss:  3.362 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████▎                      | 92/200 [03:34<04:12,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 training loss:  3.362 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████▌                      | 93/200 [03:37<04:09,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 training loss:  3.361 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████▋                      | 94/200 [03:39<04:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 training loss:  3.361 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████▉                      | 95/200 [03:41<04:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 training loss:  3.360 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████▏                     | 96/200 [03:44<04:02,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 training loss:  3.360 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████▎                     | 97/200 [03:46<04:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 training loss:  3.359 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████▌                     | 98/200 [03:48<03:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 training loss:  3.359 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▊                     | 99/200 [03:51<03:55,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 training loss:  3.358 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▌                    | 100/200 [03:53<03:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 training loss:  3.358 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████▋                    | 101/200 [03:55<03:51,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 training loss:  3.357 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████▉                    | 102/200 [03:58<03:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 101 training loss:  3.357 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████                    | 103/200 [04:00<03:46,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102 training loss:  3.356 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████▎                   | 104/200 [04:02<03:43,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103 training loss:  3.355 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████▌                   | 105/200 [04:05<03:42,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104 training loss:  3.355 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████▋                   | 106/200 [04:07<03:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105 training loss:  3.354 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████████▉                   | 107/200 [04:09<03:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106 training loss:  3.354 training accuracy:  10.9%  test loss:  3.403 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████▏                  | 108/200 [04:12<03:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 training loss:  3.353 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████▎                  | 109/200 [04:14<03:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108 training loss:  3.353 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████▌                  | 110/200 [04:16<03:30,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109 training loss:  3.352 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████▊                  | 111/200 [04:19<03:27,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110 training loss:  3.351 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████▉                  | 112/200 [04:21<03:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 111 training loss:  3.351 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████▏                 | 113/200 [04:23<03:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 training loss:  3.350 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████▎                 | 114/200 [04:26<03:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 training loss:  3.349 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████▌                 | 115/200 [04:28<03:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114 training loss:  3.349 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████▊                 | 116/200 [04:31<03:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115 training loss:  3.348 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████▉                 | 117/200 [04:33<03:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 training loss:  3.347 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████▏                | 118/200 [04:35<03:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117 training loss:  3.347 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▍                | 119/200 [04:38<03:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118 training loss:  3.346 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▌                | 120/200 [04:40<03:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119 training loss:  3.345 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████▊                | 121/200 [04:42<03:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 training loss:  3.345 training accuracy:  10.9%  test loss:  3.404 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████                | 122/200 [04:45<03:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121 training loss:  3.344 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████▏               | 123/200 [04:47<02:59,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 122 training loss:  3.343 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████▍               | 124/200 [04:49<02:57,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123 training loss:  3.343 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████▋               | 125/200 [04:52<02:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124 training loss:  3.342 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████▊               | 126/200 [04:54<02:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125 training loss:  3.341 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████               | 127/200 [04:56<02:50,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 126 training loss:  3.341 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████▏              | 128/200 [04:59<02:48,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127 training loss:  3.340 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████▍              | 129/200 [05:01<02:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 128 training loss:  3.339 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████▋              | 130/200 [05:03<02:43,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129 training loss:  3.338 training accuracy:  10.9%  test loss:  3.405 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████▊              | 131/200 [05:06<02:41,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130 training loss:  3.338 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|███████████████████████████              | 132/200 [05:08<02:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 131 training loss:  3.337 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|███████████████████████████▎             | 133/200 [05:10<02:36,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132 training loss:  3.336 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████▍             | 134/200 [05:13<02:34,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 training loss:  3.335 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████▋             | 135/200 [05:15<02:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 134 training loss:  3.334 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████▉             | 136/200 [05:17<02:29,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 training loss:  3.334 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████             | 137/200 [05:20<02:28,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136 training loss:  3.333 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████▎            | 138/200 [05:22<02:26,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 training loss:  3.332 training accuracy:  10.9%  test loss:  3.406 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████▍            | 139/200 [05:24<02:23,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138 training loss:  3.331 training accuracy:  10.9%  test loss:  3.407 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████▋            | 140/200 [05:27<02:20,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 139 training loss:  3.330 training accuracy:  10.9%  test loss:  3.407 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████▉            | 141/200 [05:29<02:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140 training loss:  3.329 training accuracy:  10.9%  test loss:  3.407 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████            | 142/200 [05:31<02:15,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141 training loss:  3.328 training accuracy:  10.9%  test loss:  3.407 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████▎           | 143/200 [05:34<02:13,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 142 training loss:  3.327 training accuracy:  10.9%  test loss:  3.407 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████▌           | 144/200 [05:36<02:10,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143 training loss:  3.327 training accuracy:  10.9%  test loss:  3.408 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████▋           | 145/200 [05:38<02:08,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 144 training loss:  3.326 training accuracy:  10.9%  test loss:  3.408 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████▉           | 146/200 [05:41<02:06,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145 training loss:  3.325 training accuracy:  10.9%  test loss:  3.408 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████▏          | 147/200 [05:43<02:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146 training loss:  3.324 training accuracy:  10.9%  test loss:  3.408 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████▎          | 148/200 [05:45<02:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147 training loss:  3.323 training accuracy:  10.9%  test loss:  3.408 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████▌          | 149/200 [05:48<02:01,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148 training loss:  3.322 training accuracy:  10.9%  test loss:  3.409 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████▊          | 150/200 [05:50<01:59,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149 training loss:  3.321 training accuracy:  10.9%  test loss:  3.409 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████▉          | 151/200 [05:53<01:57,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150 training loss:  3.320 training accuracy:  10.9%  test loss:  3.409 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████▏         | 152/200 [05:55<01:54,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 151 training loss:  3.319 training accuracy:  10.9%  test loss:  3.409 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████▎         | 153/200 [05:57<01:51,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 152 training loss:  3.318 training accuracy:  10.9%  test loss:  3.410 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████▌         | 154/200 [06:00<01:48,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 153 training loss:  3.317 training accuracy:  10.9%  test loss:  3.410 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████▊         | 155/200 [06:02<01:45,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 154 training loss:  3.315 training accuracy:  10.9%  test loss:  3.410 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████▉         | 156/200 [06:04<01:43,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 training loss:  3.314 training accuracy:  10.9%  test loss:  3.410 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████▏        | 157/200 [06:07<01:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 156 training loss:  3.313 training accuracy:  10.9%  test loss:  3.411 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████▍        | 158/200 [06:09<01:38,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 157 training loss:  3.312 training accuracy:  10.9%  test loss:  3.411 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████▌        | 159/200 [06:11<01:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 158 training loss:  3.311 training accuracy:  10.9%  test loss:  3.411 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████▊        | 160/200 [06:14<01:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159 training loss:  3.310 training accuracy:  10.9%  test loss:  3.412 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████        | 161/200 [06:16<01:31,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160 training loss:  3.309 training accuracy:  10.9%  test loss:  3.412 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████▏       | 162/200 [06:18<01:29,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 161 training loss:  3.307 training accuracy:  10.9%  test loss:  3.412 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████▍       | 163/200 [06:21<01:26,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 162 training loss:  3.306 training accuracy:  10.9%  test loss:  3.413 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████▌       | 164/200 [06:23<01:24,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 163 training loss:  3.305 training accuracy:  10.9%  test loss:  3.413 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████▊       | 165/200 [06:25<01:22,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164 training loss:  3.304 training accuracy:  10.9%  test loss:  3.414 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████       | 166/200 [06:28<01:19,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 165 training loss:  3.303 training accuracy:  10.9%  test loss:  3.414 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████▏      | 167/200 [06:30<01:17,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166 training loss:  3.301 training accuracy:  10.9%  test loss:  3.414 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████▍      | 168/200 [06:32<01:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 167 training loss:  3.300 training accuracy:  10.9%  test loss:  3.415 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████▋      | 169/200 [06:35<01:12,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 training loss:  3.299 training accuracy:  10.9%  test loss:  3.415 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|██████████████████████████████████▊      | 170/200 [06:37<01:10,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 169 training loss:  3.297 training accuracy:  10.9%  test loss:  3.416 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████      | 171/200 [06:40<01:08,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 training loss:  3.296 training accuracy:  10.9%  test loss:  3.416 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████▎     | 172/200 [06:42<01:06,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 171 training loss:  3.295 training accuracy:  10.9%  test loss:  3.417 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████▍     | 173/200 [06:44<01:03,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 training loss:  3.293 training accuracy:  10.9%  test loss:  3.417 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████▋     | 174/200 [06:47<01:01,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 173 training loss:  3.292 training accuracy:  10.9%  test loss:  3.418 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████▉     | 175/200 [06:49<00:58,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 174 training loss:  3.291 training accuracy:  10.9%  test loss:  3.419 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████     | 176/200 [06:51<00:56,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 training loss:  3.289 training accuracy:  10.9%  test loss:  3.419 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████▎    | 177/200 [06:54<00:54,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 176 training loss:  3.288 training accuracy:  10.9%  test loss:  3.420 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████▍    | 178/200 [06:56<00:51,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 177 training loss:  3.286 training accuracy:  10.9%  test loss:  3.421 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████▋    | 179/200 [06:58<00:49,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 178 training loss:  3.285 training accuracy:  10.9%  test loss:  3.421 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████▉    | 180/200 [07:01<00:46,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 179 training loss:  3.283 training accuracy:  10.9%  test loss:  3.422 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████    | 181/200 [07:03<00:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180 training loss:  3.282 training accuracy:  10.9%  test loss:  3.423 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████▎   | 182/200 [07:05<00:42,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181 training loss:  3.280 training accuracy:  10.9%  test loss:  3.423 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████▌   | 183/200 [07:08<00:40,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 182 training loss:  3.279 training accuracy:  10.9%  test loss:  3.424 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████▋   | 184/200 [07:10<00:37,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 183 training loss:  3.277 training accuracy:  10.9%  test loss:  3.425 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████▉   | 185/200 [07:13<00:35,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 184 training loss:  3.275 training accuracy:  10.9%  test loss:  3.426 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████▏  | 186/200 [07:15<00:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 training loss:  3.274 training accuracy:  10.9%  test loss:  3.427 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████▎  | 187/200 [07:17<00:30,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 186 training loss:  3.272 training accuracy:  10.9%  test loss:  3.428 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████▌  | 188/200 [07:20<00:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187 training loss:  3.271 training accuracy:  10.9%  test loss:  3.429 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████▋  | 189/200 [07:22<00:25,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188 training loss:  3.269 training accuracy:  10.9%  test loss:  3.430 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████▉  | 190/200 [07:24<00:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189 training loss:  3.267 training accuracy:  10.9%  test loss:  3.431 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████▏ | 191/200 [07:27<00:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190 training loss:  3.266 training accuracy:  10.9%  test loss:  3.432 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████▎ | 192/200 [07:29<00:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191 training loss:  3.264 training accuracy:  10.9%  test loss:  3.433 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████▌ | 193/200 [07:31<00:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 192 training loss:  3.262 training accuracy:  10.9%  test loss:  3.434 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████▊ | 194/200 [07:34<00:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 193 training loss:  3.261 training accuracy:  10.9%  test loss:  3.436 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████████████▉ | 195/200 [07:36<00:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 194 training loss:  3.259 training accuracy:  10.9%  test loss:  3.437 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████▏| 196/200 [07:38<00:09,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195 training loss:  3.257 training accuracy:  10.9%  test loss:  3.438 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████▍| 197/200 [07:41<00:07,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 196 training loss:  3.255 training accuracy:  10.9%  test loss:  3.439 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|████████████████████████████████████████▌| 198/200 [07:43<00:04,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 197 training loss:  3.254 training accuracy:  10.9%  test loss:  3.441 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|████████████████████████████████████████▊| 199/200 [07:46<00:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198 training loss:  3.252 training accuracy:  10.9%  test loss:  3.442 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [07:48<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 training loss:  3.250 training accuracy:  10.9%  test loss:  3.444 test accuracy:  3.3%\n",
      "CPU times: user 10min 19s, sys: 19.9 s, total: 10min 39s\n",
      "Wall time: 7min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nepochs = 200\n",
    "resultspath_singlebatch = root+'/resultsnew/cnn_singlebatch.pt'\n",
    "statsrec = np.zeros((4,nepochs))\n",
    "\n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_v1.parameters(), lr=0.001, momentum=0.9)\n",
    "#inputs, lab = next(iter(training_loader))\n",
    "\n",
    "iteration = iter(training_loader)\n",
    "images_s, labels_s = next(iteration)\n",
    "inputs, labels = images_s.to(device), labels_s.to(device)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(nepochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    crct = 0            # number of examples predicted correctly (for accuracy)  \n",
    "    total = 0           # number of examples    \n",
    "    runningloss = 0.0   # accumulated loss (for mean loss)   \n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out_puts = cnn_v1(inputs)\n",
    "    loss = lossfunction(out_puts, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    runningloss = loss.item()\n",
    "    \n",
    "    #accuracy\n",
    "    _, predicted = torch.max(out_puts.data, 1)\n",
    "    total += labels.size(0)    \n",
    "    crct += (predicted == labels).sum().item()  \n",
    "    #for record\n",
    "    ltrn = runningloss\n",
    "    atrn = crct/total \n",
    "    ltst, atst = stats(validation_loader, cnn_v1)\n",
    "    statsrec[:,epoch] = (ltrn, atrn, ltst.cpu(), atst)\n",
    "    print(f\"epoch: {epoch} training loss: {ltrn: .3f} training accuracy: {atrn: .1%}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "\n",
    "\n",
    "torch.save({\"state_dict\": cnn_v1.state_dict(), \"stats\": statsrec}, resultspath_singlebatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultspath_singlebatch = root+'/resultsnew/cnn_singlebatch.pt'\n",
    "data = torch.load(resultspath_singlebatch)\n",
    "statsrec = data[\"stats\"]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
    "plt.plot(statsrec[2], 'g', label = 'test loss' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and test loss, and test accuracy')\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
    "ax2.plot(statsrec[3], 'b', label = 'test accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "fig.savefig(\"mod.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "wXjATLCxQjQH",
    "outputId": "57eb5dea-c2f0-4086-a5cb-7afb73ea03c1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultspath_singlebatch = root+'/resultsnew/cnn_singlebatch.pt'\n",
    "data = torch.load(resultspath_singlebatch)\n",
    "statsrec = data[\"stats\"]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
    "plt.plot(statsrec[2], 'g', label = 'test loss' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and test loss, and test accuracy')\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
    "ax2.plot(statsrec[3], 'b', label = 'test accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "fig.savefig(\"mod.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdV9BOs2QjQH"
   },
   "source": [
    "\n",
    "\n",
    "## 1.2 Training on complete dataset [23 marks]\n",
    "\n",
    "### 1.2.1 Train CNN and show loss graph [6 marks]\n",
    "\n",
    "Train your model on the complete training dataset, and use the validation set to determine when to stop training.\n",
    "\n",
    "Display the graph of training and validation loss over epochs to show how you determined the optimal number of training epochs.\n",
    "\n",
    "> As in previous sections, please leave the graph clearly displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6AcHMXJVQjQH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss:  3.400 training accuracy:  3.7%  test loss:  3.399 test accuracy:  3.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 training loss:  3.398 training accuracy:  4.2%  test loss:  3.397 test accuracy:  3.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 training loss:  3.395 training accuracy:  3.7%  test loss:  3.393 test accuracy:  4.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 training loss:  3.389 training accuracy:  4.8%  test loss:  3.385 test accuracy:  6.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 training loss:  3.376 training accuracy:  6.2%  test loss:  3.366 test accuracy:  7.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 training loss:  3.340 training accuracy:  7.9%  test loss:  3.306 test accuracy:  9.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 training loss:  3.245 training accuracy:  10.2%  test loss:  3.184 test accuracy:  12.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 training loss:  3.122 training accuracy:  12.9%  test loss:  3.067 test accuracy:  13.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 training loss:  3.012 training accuracy:  15.0%  test loss:  3.004 test accuracy:  14.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 training loss:  2.949 training accuracy:  16.3%  test loss:  2.945 test accuracy:  15.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 training loss:  2.894 training accuracy:  17.8%  test loss:  2.927 test accuracy:  16.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 training loss:  2.839 training accuracy:  19.3%  test loss:  2.892 test accuracy:  17.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 training loss:  2.801 training accuracy:  20.4%  test loss:  2.862 test accuracy:  18.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 training loss:  2.761 training accuracy:  21.5%  test loss:  2.835 test accuracy:  19.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 training loss:  2.723 training accuracy:  22.5%  test loss:  2.793 test accuracy:  20.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 training loss:  2.691 training accuracy:  23.1%  test loss:  2.812 test accuracy:  20.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 training loss:  2.638 training accuracy:  24.6%  test loss:  2.741 test accuracy:  22.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 training loss:  2.602 training accuracy:  25.9%  test loss:  2.709 test accuracy:  23.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 training loss:  2.553 training accuracy:  27.5%  test loss:  2.701 test accuracy:  23.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 training loss:  2.515 training accuracy:  28.5%  test loss:  2.624 test accuracy:  25.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 training loss:  2.463 training accuracy:  29.4%  test loss:  2.613 test accuracy:  24.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 training loss:  2.421 training accuracy:  30.6%  test loss:  2.556 test accuracy:  27.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 training loss:  2.378 training accuracy:  32.1%  test loss:  2.540 test accuracy:  28.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 training loss:  2.330 training accuracy:  32.9%  test loss:  2.501 test accuracy:  28.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 training loss:  2.290 training accuracy:  34.4%  test loss:  2.494 test accuracy:  28.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 training loss:  2.233 training accuracy:  35.6%  test loss:  2.480 test accuracy:  28.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 training loss:  2.184 training accuracy:  37.0%  test loss:  2.419 test accuracy:  30.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 training loss:  2.140 training accuracy:  38.2%  test loss:  2.379 test accuracy:  31.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 training loss:  2.092 training accuracy:  39.5%  test loss:  2.382 test accuracy:  31.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 training loss:  2.039 training accuracy:  41.2%  test loss:  2.421 test accuracy:  31.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 training loss:  1.992 training accuracy:  41.7%  test loss:  2.361 test accuracy:  31.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 training loss:  1.941 training accuracy:  43.7%  test loss:  2.364 test accuracy:  32.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 training loss:  1.900 training accuracy:  45.3%  test loss:  2.276 test accuracy:  34.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 training loss:  1.852 training accuracy:  46.0%  test loss:  2.297 test accuracy:  34.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 training loss:  1.798 training accuracy:  47.7%  test loss:  2.294 test accuracy:  35.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 training loss:  1.756 training accuracy:  49.6%  test loss:  2.285 test accuracy:  34.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 training loss:  1.707 training accuracy:  50.2%  test loss:  2.292 test accuracy:  35.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 training loss:  1.668 training accuracy:  51.2%  test loss:  2.306 test accuracy:  34.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 training loss:  1.615 training accuracy:  53.1%  test loss:  2.375 test accuracy:  34.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 training loss:  1.574 training accuracy:  53.8%  test loss:  2.329 test accuracy:  35.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 training loss:  1.514 training accuracy:  55.6%  test loss:  2.370 test accuracy:  34.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 training loss:  1.475 training accuracy:  56.5%  test loss:  2.441 test accuracy:  33.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [00:13<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n",
      "CPU times: user 13min 28s, sys: 21 s, total: 13min 49s\n",
      "Wall time: 11min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TO COMPLETE\n",
    "#nepochs = 300\n",
    "nepochs = 200\n",
    "epochs_stop = 10\n",
    "improve = 0\n",
    "\n",
    "earlystop=False\n",
    "\n",
    "resultspath_fulldataset = root+'/resultsnew/cnn_fulldataset.pt'\n",
    "statsrec = np.zeros((4,nepochs))\n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(cnn_v1.parameters(), lr=0.001, momentum=0.9)\n",
    "minimumvalloss=np.Inf\n",
    "\n",
    "for epoch in range(nepochs):  \n",
    "    crct = 0         \n",
    "    total = 0            \n",
    "    runningloss = 0.0   \n",
    "    n = 0                \n",
    "    for data in tqdm(training_loader):\n",
    "        image_s, label_s = data\n",
    "        images, labels = image_s.to(device), label_s.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out_puts = cnn_v1(images)\n",
    "        \n",
    "        loss = lossfunction(out_puts, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        runningloss += loss.item()\n",
    "        n += 1\n",
    "        \n",
    "        \n",
    "        _, predicted = torch.max(out_puts.data, 1)\n",
    "        total += labels.size(0)   \n",
    "        crct += (predicted == labels).sum().item() \n",
    "        \n",
    "        \n",
    "    ltrn = runningloss/n\n",
    "    atrn = crct/total \n",
    "    ltst, atst = stats(validation_loader, cnn_v1)\n",
    "    if ltst<minimumvalloss:\n",
    "        epochs_no_improve = 0\n",
    "        minimumvalloss = ltst\n",
    "    else:\n",
    "        epochs_no_improve+=1\n",
    "        \n",
    "    if epoch > 5 and epochs_no_improve == epochs_stop:\n",
    "        print('Early stopping!' )\n",
    "        earlystop = True\n",
    "        break\n",
    "    statsrec[:,epoch] = (ltrn,atrn, ltst.cpu(), atst)\n",
    "    print(f\"epoch: {epoch} training loss: {ltrn: .3f} training accuracy: {atrn: .1%}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "\n",
    "torch.save({\"state_dict\": cnn_v1.state_dict(), \"stats\": statsrec}, resultspath_fulldataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "sk_CkRf1QjQI",
    "outputId": "61894520-8191-4b47-b255-5b49d32354fe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultspath_fulldataset = root+'/resultsnew/cnn_fulldataset.pt'\n",
    "data = torch.load(resultspath_fulldataset)\n",
    "statsrec = data[\"stats\"]\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
    "plt.plot(statsrec[2], 'g', label = 'test loss' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and test loss, and test accuracy')\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
    "ax2.plot(statsrec[3], 'b', label = 'test accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "fig.savefig(\"mod1.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYBlu0W1QjQI"
   },
   "source": [
    "\n",
    "### 1.2.2 Finetuning [6 marks]\n",
    "\n",
    "Now finetune your architecture by implementing at least 2 methods of reducing overfitting and increasing the model's ability to generalise. You are encouraged to further adjust the model after you have done the minimum requirement, to increase your model performance. Please do not use any pre-trained weights from a model trained on ImageNet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODwxZaMRQjQJ"
   },
   "source": [
    "**Method 1:** Data augmentation of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3I_wmSLQjQJ"
   },
   "source": [
    "**Method 2:** Adding dropout and/or batch normalisation to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh3CR-uxQjQJ"
   },
   "source": [
    "If you adjust the Model class, redefine it below and instantiate it as ```model_122a```, ```model_122b```, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_ncUe3VGPIZ",
    "outputId": "33c52455-772b-47d0-8abc-9f4881c6e596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 13500\n",
      "    Root location: ./data/train_set/train_set\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomVerticalFlip(p=0.05)\n",
      "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "           )\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([                        \n",
    "   transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.05),\n",
    "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root+'/train_set/train_set',transform=transform)\n",
    "print(dataset)\n",
    "print(len(dataset.classes))\n",
    "training_loader= int(0.80 * len(dataset))\n",
    "validation_size = len(dataset) - training_size\n",
    "training_dataset, validation_dataset = torch.utils.data.random_split(dataset, [training_size, validation_size])\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset,batch_size=64, shuffle=True,num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=64, shuffle=True,num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "268wWJkdQjQJ",
    "outputId": "713a416d-7dc0-4ea2-8900-e0bd17cc5b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 3, 3])\n",
      "torch.Size([50])\n",
      "torch.Size([75, 50, 3, 3])\n",
      "torch.Size([75])\n",
      "torch.Size([125, 75, 3, 3])\n",
      "torch.Size([125])\n",
      "torch.Size([256, 125, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([1000, 16384])\n",
      "torch.Size([1000])\n",
      "torch.Size([500, 1000])\n",
      "torch.Size([500])\n",
      "torch.Size([200, 500])\n",
      "torch.Size([200])\n",
      "torch.Size([30, 200])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# Adding drop out\n",
    "model_122a = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=50, kernel_size=3,padding=1),  \n",
    "    nn.ReLU(inplace=True), \n",
    "    nn.Conv2d(in_channels=50,out_channels=75,  kernel_size=3,padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.5),  \n",
    "    nn.Conv2d(in_channels=75,out_channels=125,  kernel_size=3,padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=125,out_channels=256,  kernel_size=3,padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(p=0.25),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256*8*8,1000), \n",
    "    nn.Dropout(p=0.25),  \n",
    "    nn.Linear(1000,500),\n",
    "    nn.Dropout(p=0.25),  \n",
    "    nn.Linear(500,200),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(200,30)\n",
    ")\n",
    "\n",
    "cnn_v3 = model_122a.to(device)\n",
    "\n",
    "for param in cnn_v3.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([84, 128])\n",
      "torch.Size([84])\n",
      "torch.Size([30, 84])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "model_122b = nn.Sequential (\n",
    "    nn.Conv2d(3,6,5),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6,16,5),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(16,32,5),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32*4*4,128),\n",
    "    nn.Linear(128, 84),\n",
    "    nn.Linear(84, 30)\n",
    ")\n",
    "\n",
    "cnn_v3 = model_122b.to(device)\n",
    "for param in cnn_v3.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 82944])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([30, 512])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_122c = nn.Sequential (\n",
    "    nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(82944,1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,30)\n",
    ")\n",
    "\n",
    "cnn_v3 = model_122c.to(device)\n",
    "for param in cnn_v3.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KAYz_yT7rp9U"
   },
   "outputs": [],
   "source": [
    "def stats1(loader, cnn_v3):\n",
    "    crct = 0\n",
    "    total = 0\n",
    "    runningloss = 0\n",
    "    n = 0    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            image_s, label_s = data\n",
    "            images, labels = image_s.to(device), label_s.to(device)\n",
    "            \n",
    "            out_puts = cnn_v3(images)      \n",
    "            runningloss += lossfunction(out_puts, labels)\n",
    "            n += 1\n",
    "            _, predicted = torch.max(out_puts.data, 1)\n",
    "            total += labels.size(0)    \n",
    "            crct += (predicted == labels).sum().item() \n",
    "            \n",
    "    return runningloss/n, crct/total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaHJ1QtQQjQK",
    "outputId": "30b2d0fd-06e9-4c86-ad88-95c5ed6edd0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:09<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss:  3.402 training accuracy:  3.4%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:00<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 training loss:  3.402 training accuracy:  3.3%  test loss:  3.402 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:03<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 training loss:  3.402 training accuracy:  3.6%  test loss:  3.402 test accuracy:  2.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:03<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 training loss:  3.402 training accuracy:  3.7%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:04<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 training loss:  3.401 training accuracy:  3.6%  test loss:  3.401 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:02<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 training loss:  3.402 training accuracy:  3.5%  test loss:  3.402 test accuracy:  3.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:00<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 training loss:  3.402 training accuracy:  3.5%  test loss:  3.402 test accuracy:  2.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:03<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 training loss:  3.402 training accuracy:  3.2%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:02<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 training loss:  3.402 training accuracy:  3.8%  test loss:  3.402 test accuracy:  3.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [09:59<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 training loss:  3.402 training accuracy:  3.8%  test loss:  3.401 test accuracy:  3.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [09:59<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 training loss:  3.402 training accuracy:  3.4%  test loss:  3.402 test accuracy:  3.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 148/148 [10:00<00:00,  3.58s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nepochs = 20\n",
    "\n",
    "resultspath_finetuned = root+'/resultsnew/cnn_finetuned.pt'\n",
    "statsrec = np.zeros((4,nepochs))\n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.Adam(cnn_v3.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5)\n",
    "minimumvalloss=np.Inf\n",
    "for epoch in (range(nepochs)): \n",
    "    crct = 0          \n",
    "    total = 0            \n",
    "    runningloss = 0.0   \n",
    "    n = 0\n",
    "    for data in tqdm(training_loader):\n",
    "        image_s, label_s = data\n",
    "        images, labels = image_s.to(device), label_s.to(device)\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        out_puts = cnn_v3(images)\n",
    "        loss = lossfunction(out_puts, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningloss += loss.item()\n",
    "        n += 1\n",
    "        _, predicted = torch.max(out_puts.data, 1)\n",
    "        total += labels.size(0)   \n",
    "        crct += (predicted == labels).sum().item() \n",
    "    ltrn = runningloss/n\n",
    "    atrn = crct/total \n",
    "    ltst, atst = stats1(validation_loader, cnn_v3)\n",
    "    scheduler.step(ltst/len(validation_loader))\n",
    "    statsrec[:,epoch] = (ltrn, atrn, ltst.cpu(), atst)\n",
    "    print(f\"epoch: {epoch} training loss: {ltrn: .3f} training accuracy: {atrn: .1%}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "\n",
    "torch.save({\"state_dict\": cnn_v3.state_dict(), \"stats\": statsrec}, resultspath_finetuned)\n",
    "\n",
    "notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "AF7c47HZQjQK",
    "outputId": "20f35d8f-7a3a-4b60-aa4a-1768b050cab0"
   },
   "outputs": [],
   "source": [
    "resultspath_finetuned = root+'/resultsnew/cnn_finetuned.pt'\n",
    "data = torch.load(resultspath_finetuned)\n",
    "statsrec = data[\"stats\"]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
    "plt.plot(statsrec[2], 'g', label = 'test loss' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and test loss, and test accuracy')\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
    "ax2.plot(statsrec[3], 'b', label = 'test accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "fig.savefig(\"mod1.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b8jfwpTQjQK"
   },
   "source": [
    "\n",
    "### 1.2.3 Training comparison [4 marks]\n",
    "\n",
    "Display, side-by-side or on one single graph, the training and validation loss graphs for the single-batch training (section 1.1.3), on the full training set (1.2.1) and your final fine-tuned model (1.2.2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "ueTMTUT-QjQL",
    "outputId": "74f1dae3-0de7-4720-8424-f49814cd6c1a"
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(2,2,1)\n",
    "data = torch.load(resultspath_singlebatch)\n",
    "statsrec = data[\"stats\"]\n",
    "plt.plot(statsrec[1], 'r', label =  'training accuracy', )\n",
    "plt.plot(statsrec[3], 'g', label =  'test accuracy' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Single batch training')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "\n",
    "data = torch.load(resultspath_fulldataset)\n",
    "statsrec = data[\"stats\"]\n",
    "plt.plot(statsrec[1], 'r', label =  'training accuracy', )\n",
    "plt.plot(statsrec[3], 'g', label =  'test accuracy' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Whole training dataset training')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "\n",
    "data = torch.load(resultspath_finetuned)\n",
    "statsrec = data[\"stats\"]\n",
    "plt.plot(statsrec[1], 'r', label =  'training accuracy', )\n",
    "plt.plot(statsrec[3], 'g', label =  'test accuracy' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Finetuning training')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s41SqpxQjQL"
   },
   "source": [
    "When model is trained for single batch, its accuracy increases exponentially.\n",
    "\n",
    "While model is trained on whole data set, the model reaches full accuracy in minimal epochs but then falls to zero after wards.\n",
    "\n",
    "For the finetuning graph , we can see in both the cases, there was a sharp increase together which may lead to overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTjbO62yQjQL"
   },
   "source": [
    "\n",
    "### 1.2.4 Confusion matrices [7 marks]\n",
    "\n",
    "Use your architecture with best accuracy to generate two confusion matrices, one for the training set and one for the validation set. Remember to use the whole validation and training sets, and to include all your relevant code. Display the confusion matrices in a meaningful way which clearly indicates what percentage of the data is represented in each position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "data=torch.load(resultspath_finetuned)\n",
    "cnn_v2.load_state_dict(data[\"state_dict\"])\n",
    "cnn_v2.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "class_list=[]\n",
    "for key in dataset.class_to_idx.keys():\n",
    "    class_list.append(key)\n",
    "# iterate over test data\n",
    "for data in training_loader:\n",
    "    \n",
    "    input_s, label_s = data\n",
    "    inputs, labels = input_s.to(device), label_s.to(device)\n",
    "    output = cnn_v2(inputs) # Feed Network\n",
    "    # _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    \n",
    "   # output = predicted.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    #labels = labels.data.numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in class_list],\n",
    "                     columns = [i for i in class_list])\n",
    "plt.figure(figsize = (30,30))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('confusionmatrix_output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDoWb0SDQjQM"
   },
   "source": [
    "What conclusions can be drawn from the confusion matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkv6t5Q_QjQN"
   },
   "source": [
    "\n",
    "\n",
    "## 1.3 Testing on test data [18 marks]\n",
    "\n",
    "### 1.3.1 Dataset and generating predictions [6 marks]\n",
    "\n",
    "Create a PyTorch ```Dataset``` for the unlabeled test data in the test_set folder of the Kaggle competition and generate predictions using your final model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        input_s, label_s = data\n",
    "        inputs, labels = input_s.to(device), label_s.to(device)\n",
    "\n",
    "    outputs = cnn_v2(inputs)\n",
    "    results.extend(outputs.argmax(dim=1).type(torch.int32).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "\n",
    "results_path_finetune = root+'/resultsnew/cnn_finetuned.pt'\n",
    "data=torch.load(results_path_finetune)\n",
    "cnn_v2.load_state_dict(data[\"state_dict\"])\n",
    "cnn_v2.eval()\n",
    "dataset = LoadFromFolder(root+\"/test_set/test_set\",transform=transform )\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "predicted_list=[]\n",
    "for i in range(len(dataset)):\n",
    "    image_name, image =dataset.__getitem__(i)\n",
    "    outputs=model_122(image)#\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    data = [image_name,predicted.numpy()[0] ]  \n",
    "    predicted_list.append(data)\n",
    "    # write a row to the csv file\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MokMoqcdQjQN"
   },
   "source": [
    "\n",
    "### 1.3.2 CSV file and test set accuracy [12 marks]\n",
    "\n",
    "Save all test predictions to a CSV file and submit it to the private class Kaggle competition. **Please save your test CSV file submissions using your student username (the one with letters, ie., ``sc15jb``, not the ID with only numbers)**, for example, `sc15jb.csv`. That will help us to identify your submissions.\n",
    "\n",
    "The CSV file must contain only two columns: ‘Id’ and ‘Category’ (predicted class ID) as shown below:\n",
    "\n",
    "```txt\n",
    "Id,Category\n",
    "28d0f5e9_373c.JPEG,2\n",
    "bbe4895f_40bf.JPEG,18\n",
    "```\n",
    "\n",
    "The ‘Id’ column should include the name of the image. It is important to keep the same name as the one on the test set. Do not include any path, just the name of file (with extension). Your csv file must contain 1501 rows, one for each image on test set and 1 row for the headers.\n",
    "\n",
    "> You may submit multiple times. We will use your personal top entry for allocating marks for this [10 marks]. The class leaderboard will not affect marking (brownie points!).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "\n",
    "with open(\"/content/drive/MyDrive/AI/sc21vp.csv\", 'a', newline='') as f_object:  \n",
    "    # Pass the CSV  file object to the writer() function\n",
    "    writer_object = writer(f_object)\n",
    "    # Result - a writer object\n",
    "    # Pass the data in the list as an argument into the writerow() function\n",
    "    for list_data in predicted_list:\n",
    "     writer_object.writerow(list_data)  \n",
    "    # Close the file object\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "\n",
    "dataset1 = DataLoader(root+'/test_set/test_set',transform=transform )\n",
    "\n",
    "prediction = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataset1:\n",
    "        inputs, labels = data\n",
    "        #inputs, labels = input_s.to(device), label_s.to(device)\n",
    "\n",
    "    outputs = cnn_v2(inputs)\n",
    "    #results.extend(outputs.argmax(dim=1).type(torch.int32).cpu().numpy())\n",
    "    _, predicted1 = torch.max(output.data, 1)\n",
    "    data1 = [labels,predicted1.numpy()[0] ]  \n",
    "    prediction.append(data1)\n",
    "\n",
    "    \n",
    "with open(\"sc21kj.csv\", 'a', newline='') as f_object:  \n",
    "    w_obj = writer(f_object)\n",
    "    for data1 in prediction:\n",
    "        w_obj.writerow(data1)\n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_sR8Gc04CJ2"
   },
   "source": [
    "\n",
    "\n",
    "## QUESTION 2 [40 marks]\n",
    "\n",
    "\n",
    "\n",
    "In this question, you will visualize the filters and feature maps of a fully-trained CNN (AlexNet) on the full ImageNet 2012 dataset.\n",
    "\n",
    "> Please do not alter the name of the function or the number and type of its arguments and return values, otherwise the automatic grading function will not work correctly. You are welcome to import other modules (though the simplest solution only requires the ones below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-HIUgQ-HK8Y"
   },
   "source": [
    "### **Overview:**\n",
    "*   **2.1.1** Extract filters from model: ``fetch_filters(layer_idx, model)``\n",
    "*   **2.2.1** Load test image\n",
    "*   **2.2.2** Extract feature maps for given test image: ``fetch_feature_maps(image, model)``\n",
    "*   **2.2.3** Display feature maps\n",
    "*   **2.3.1** Generate Grad-CAM heatmaps: ``generate_heatmap(output, class_id, model, image)``\n",
    "*   **2.3.2** Display heatmaps: add code to cell\n",
    "*   **2.3.3** Generate heatmaps for failure analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gYdjXng4CJ5"
   },
   "source": [
    "### Loading a pre-trained model\n",
    "\n",
    "Run the cell below to load an AlexNet model with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ik9dzD4S4CJ6",
    "outputId": "e9a22add-df1b-46fe-9c3b-8a858742be63"
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKFVSrm1QjQQ",
    "outputId": "d90d2879-479f-4946-8df9-b17d3ba12e9a"
   },
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sqd6RveQjQQ",
    "outputId": "8be87f11-199f-46fb-aa4e-c18f73f51c94"
   },
   "outputs": [],
   "source": [
    "model.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJXmdjo6QjQR",
    "outputId": "85d6f206-7752-427f-82ab-9d2b2cbd3711"
   },
   "outputs": [],
   "source": [
    "model.features[0].weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXzlLbstCE7f"
   },
   "source": [
    "\n",
    "## 2.1 Extract and visualize the filters [6 marks]\n",
    "\n",
    "In this section you will extract and visualize the filters from the pre-trained AlexNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vOrqr2J4CJ7"
   },
   "source": [
    "### 2.1.1 Extract filters [4 marks]\n",
    "\n",
    "Complete the following function ```fetch_filters``` to return all the filters from the convolutional layers at the given index in ```model.features``` (see printed model above for reference). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> We will not test the behaviour of your function using invalid indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdbDXckn4CJ8"
   },
   "outputs": [],
   "source": [
    "def fetch_filters(layer_idx, model):\n",
    "    \"\"\" \n",
    "        Args:\n",
    "            layer_idx (int): the index of model.features specifying which conv layer\n",
    "            model (AlexNet): PyTorch AlexNet object\n",
    "        Return:\n",
    "            filters (Tensor):      \n",
    "    \"\"\"\n",
    "    filters = model.features[layer_idx].weight.data.clone()\n",
    "     \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNxPI5y-4CJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "conv_layer_idx = [0, 3, 6, 8, 10]\n",
    "\n",
    "filters = []\n",
    "\n",
    "for layer_idx in conv_layer_idx:\n",
    "    filters.append(fetch_filters(layer_idx, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWSpX94c4CKD"
   },
   "source": [
    "For your testing purposes, the following code blocks test the dimensions of the function output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXeQtKkK4CKE",
    "outputId": "90c9bf76-c3d8-4d29-b294-c28d1788043e"
   },
   "outputs": [],
   "source": [
    "filters[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZnC8Eth4CKF"
   },
   "outputs": [],
   "source": [
    "assert list(filters[0].shape) == [64, 3, 11, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECx7Ktsg4CKG"
   },
   "source": [
    "\n",
    "\n",
    "### 2.1.2 Display filters [2 marks]\n",
    "\n",
    "The following code will visualize some of the filters from each layer. Play around with viewing filters at different depths into the network. Note that ```filters[0]``` could be viewed in colour if you prefer, whereas the subsequent layers must be viewed one channel at a time in grayscale. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "7K6N3ThU4CKG",
    "outputId": "d11ce90d-bd58-49b5-9ec3-4413141d8fa6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "to_show = 16\n",
    "\n",
    "\n",
    "plt_dim = int(math.sqrt(to_show))\n",
    "\n",
    "\n",
    "for i, filt in enumerate(filters[0].numpy()[:to_show]):\n",
    "    plt.subplot(plt_dim, plt_dim, i+1)\n",
    "    plt.imshow(filt[0], cmap=\"Greens\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCJF9IIF4CKI"
   },
   "source": [
    "\n",
    "\n",
    "## 2.2 Extract and visualize feature maps [10 marks]\n",
    "\n",
    "In this section, you will pass a test image through the AlexNet and extract and visualize the resulting convolutional layer feature maps.\n",
    "\n",
    "Complete the following code cell to load the test image ```man_bike.JPEG```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVfEgbC4I_dE"
   },
   "source": [
    "### 2.2.1 Load test image [1 mark]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xypfUN7y4CKI",
    "outputId": "be4aaef6-7975-429c-e46c-c83adc8db1e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "im=Image.open(root+'/man_bike.JPEG').convert(\"RGB\")\n",
    "print(im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aF2t9uOk4CKJ"
   },
   "source": [
    "Run the code cell below to apply the image transformation expected by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jt0tJQsM4CKO"
   },
   "outputs": [],
   "source": [
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean, norm_std),\n",
    "    ])\n",
    "\n",
    "im = data_transform(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VQKNo384CKP"
   },
   "source": [
    "\n",
    "### 2.2.2 Extract feature maps [5 marks]\n",
    "\n",
    "Complete the function below to pass the test image through a single forward pass of the network. We are interested in the outputs of the max pool layers (outputs of conv layers at model.features indices 0, 3, and 10) for best visualization. Note that the input should pass through *every layer* of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmqQ_mJ54CKP"
   },
   "outputs": [],
   "source": [
    "def fetch_feature_maps(image, model):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image (Tensor): a single input image with transform applied\n",
    "        model (AlexNet): PyTorch AlexNet object\n",
    "        \n",
    "    Return:\n",
    "        feature_maps (Tensor): all the feature maps from conv layers \n",
    "                    at indices 0, 3, and 10 (outputs of the MaxPool layers)\n",
    "    \"\"\"\n",
    "     \n",
    "    \n",
    "    model_weights =[]\n",
    "   \n",
    "    conv_layers = []\n",
    "   \n",
    "    all_layers=[]\n",
    "    counter = 0 \n",
    "    maxpool=[]\n",
    "    model_children = list(model.children())\n",
    "\n",
    "    for j in range(len(model_children[0])):\n",
    "        child= model_children[0][j]\n",
    "        all_layers.append(child)\n",
    "        if type(child) == nn.MaxPool2d:\n",
    "            \n",
    "            counter += 1\n",
    " \n",
    "\n",
    "    print(counter)\n",
    "    results = [all_layers[0](image)]\n",
    "  \n",
    "    for i in range(1, len(all_layers)):\n",
    "        \n",
    "        x=all_layers[i](results[-1])\n",
    "        results.append(x)\n",
    "        if len(results[i][0][0]) == len(results[i-1][0][0])// 2:\n",
    "            maxpool.append(x)\n",
    "       \n",
    "   \n",
    "    maxpool=[torch.tensor(x,requires_grad=False) for x in maxpool ]\n",
    "    \n",
    "    return maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORkRxCVo4CKQ",
    "outputId": "e57b1fb4-4ca7-4ccc-feda-55cde23293e3"
   },
   "outputs": [],
   "source": [
    "feature_maps = fetch_feature_maps(im.unsqueeze(0), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf3SZoFu4CKQ"
   },
   "source": [
    "For your testing purposes, the following code block tests the dimensions of part of the function output. Note that the first dimension is the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow7jGdQ94CKR"
   },
   "outputs": [],
   "source": [
    "assert len(feature_maps) == 3\n",
    "assert list(feature_maps[0].shape) == [1, 64, 31, 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDmwrp-w4CKR"
   },
   "source": [
    "\n",
    "\n",
    "### 2.2.3 Display feature maps [4 marks]\n",
    "\n",
    "Using the code for displaying filters as reference, write code in the block below to display the outputs of the first **16 feature maps from each of the 3 max-pool layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "Y2O8TZG74CKS",
    "outputId": "46759f29-fb56-4a98-d96e-d4e97e0c1f98"
   },
   "outputs": [],
   "source": [
    " # limit\n",
    "n = 16\n",
    "\n",
    " \n",
    "plt_dim = int(math.sqrt(n))\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for i, filt in enumerate(feature_maps[i][0].numpy()[:n]):\n",
    "        plt.subplot(plt_dim, plt_dim, i+1)\n",
    "        plt.imshow(filt, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZNGf5WQ4CKG"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## 2.3 Understanding of filters and feature maps [7 marks]\n",
    "\n",
    "Respond in detail to the questions below. (Note that all text boxes can be formatted using Markdown if desired).\n",
    "\n",
    "### 2.3.1 [3 marks]\n",
    "Describe what the three filters at indices 0, 4, and 6 from the first convolutional layer are detecting (reference the corresponding feature maps to support your discussion).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaSlB9g_QjQW"
   },
   "source": [
    "--> Filter 0 -> It is classifying and grouping man and block as one element. Able to see the silhoute of the man as part of fore ground. It also detects foreground elements.\n",
    "\n",
    "--> Filter 4 -> It detects much clearer picture of man's head and his torso.\n",
    "\n",
    "--> Filter 6 -> Able to identify the wheels of the cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTEOvOsSQjQW"
   },
   "source": [
    "### 2.3.2 [2 marks]\n",
    "Discuss how the filters change with depth into the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD1tIB3hQjQW"
   },
   "source": [
    "--> At first, the filters detect multiple colors and edges and is able to identify different shapes.\n",
    "\n",
    "--> At final layers, we can see more clearer image with more complex patterns that is used to identify the element in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AF-878fQjQX"
   },
   "source": [
    "### 2.3.3 [2 marks]\n",
    "Discuss how the feature maps change with depth into the network.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0iY8yStQjQX"
   },
   "source": [
    "--> As depth increases, the image is broken down into simpler blocks.\n",
    "--> At first, we will be able to see and differentiate between foreground and background scenes, but as the depth increases, it will be reduced and will be able to only see shapes that appears in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXeO_agI4CKS"
   },
   "source": [
    "\n",
    "## 2.4 Gradient-weighted Class Activation Mapping (Grad-CAM) [17 marks]\n",
    "\n",
    "In this section, we will explore using Gradient-weighted Class Activation Mapping (Grad-CAM) to generate coarse localization maps highlighting the important regions in the test images guiding the model's prediction. We will continue using the pre-trained AlexNet.\n",
    "\n",
    "#### Preparation\n",
    ">It is recommended to first read the relevant paper [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391), and refer to relevant course material.\n",
    "\n",
    "#### The AlexNet class\n",
    "\n",
    ">To implement Grad-CAM, we need to edit the AlexNet ```module``` class itself, so instead of loading the AlexNet model from ```torch.hub``` as we did above, we will use the official PyTorch AlexNet class code ([taken from here](https://pytorch.org/vision/stable/_modules/torchvision/models/alexnet.html)). In addition to the class definition, there is also a function below called ```alexnet()``` which allows you to specify whether you want the pretrained version or not, and if so, loads the weights. \n",
    "\n",
    "#### The hook\n",
    "\n",
    ">[Hooks](https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html#forward-and-backward-function-hooks) in PyTorch are functions which can be registered, or attached, to a ```Module``` or ```Tensor```. Hooks can be *forward* hooks or *backward* hooks; forward hooks are called with ```forward()``` and backward hooks with ```backward()```. In the model below, we register a forward hook that saves the **gradients of the activations** to the Tensor output of ```model.features```. The gradients are saved to a class variable so we can easily access them.\n",
    "\n",
    "Carefully read the code block below. You do not need to add anything to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74G4wPeG4CKS"
   },
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-7be5be79.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.gradients = None\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def activations_hook(self, grad):\n",
    "        \n",
    "        self.gradients = grad\n",
    "\n",
    "  \n",
    "    def get_activations(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        \n",
    "        hook = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, progress=True, **kwargs) -> AlexNet:\n",
    "    \"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FZEiLFv4CKT"
   },
   "outputs": [],
   "source": [
    "model = alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiBjgrST4CKT"
   },
   "outputs": [],
   "source": [
    "\n",
    "output = model(im.unsqueeze(0))\n",
    "_, pred_cls = output.max(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzCYhGyI4CKT"
   },
   "source": [
    "Examine and understand the values stored in ```output``` and ```pred_cls```. What does AlexNet classify the test image as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU5QjsuP4CKU",
    "outputId": "eb6fcce8-0e83-4f1d-c469-1f3106fd55ce"
   },
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "print(pred_cls)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr4svXcg4CKU"
   },
   "source": [
    "### 2.4.1 Generate Grad-CAM heatmaps [8 marks]\n",
    "\n",
    "With the hooks in place, now implement the code to generate Grad-CAM heatmaps, by following the guiding comments in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rdlr69tw4CKU"
   },
   "outputs": [],
   "source": [
    "def generate_heatmap(output, class_id, model, image):\n",
    "    \n",
    "    output[:,-1].backward()\n",
    "    \n",
    "    gradients = model.gradients\n",
    "    assert list(gradients.shape) == [1, 256, 7, 7]\n",
    "    \n",
    "    \n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    assert list(pooled_gradients.shape) == [256]\n",
    "    \n",
    "    \n",
    "    activations = model.get_activations(image).detach()\n",
    "    assert list(activations.shape) == [1, 256, 7, 7]\n",
    "    \n",
    "    \n",
    "    for i in range(256):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    assert list(heatmap.shape) == [7, 7]\n",
    "    \n",
    "   \n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "   \n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PEmi-aM4CKU"
   },
   "outputs": [],
   "source": [
    "heatmap = generate_heatmap(output, pred_cls, model, im.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaiH3MIO4CKV"
   },
   "source": [
    "Check the dimensions of ```heatmap```. Do they make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "qigb0A9F4CKV",
    "outputId": "75f22935-7ce9-4033-815c-a89ddfe102fb"
   },
   "outputs": [],
   "source": [
    "heatmap.shape \n",
    "plt.matshow(heatmap.squeeze())\n",
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvyCYUpw4CKW"
   },
   "source": [
    "### 2.4.2 Display heatmaps [4 marks]\n",
    "\n",
    "Display ```heatmap``` as a coloured heatmap super-imposed onto the original image. To get results as shown in the paper, we recommend the following steps:\n",
    "\n",
    "1. Resize the heatmap to match the size of the image.\n",
    "2. Rescale the image to a 0-255 integer range.\n",
    "3. Apply a colormap to the heatmap using ```cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)```.\n",
    "4. Multiply all values of heatmap by 0.4 to reduce colour saturation.\n",
    "5. Superimpose the heatmap onto the original image (Note: please perform cv2's addition - addition of two cv2 images, not numpy addition. See [here](https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.html#:~:text=addWeighted()%20etc.-,Image%20Addition,OpenCV%20addition%20and%20Numpy%20addition.) for explanation.)\n",
    "6. Normalize the image between 0-255 again.\n",
    "7. Display the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "GwTIJoh84CKX",
    "outputId": "466011bd-281f-4904-c892-5c43d60c7a04"
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_heatmap(heatmap,image):\n",
    "    (w, h) = (image.shape[0], image.shape[1])\n",
    "    heatmap = cv2.resize(heatmap.numpy(), (w, h))\n",
    "    \n",
    "    numer = heatmap - np.min(heatmap)\n",
    "    denom = (heatmap.max() - heatmap.min()) + 1e-8\n",
    "    heatmap_normalized = numer / denom\n",
    "    heatmap_normalized = (heatmap_normalized * 255).astype(\"uint8\")\n",
    "\n",
    "    heatmap_normalized = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)\n",
    "    \n",
    "    heatmap_normalized=heatmap_normalized * 0.4\n",
    "    \n",
    "    weighted_image= cv2.addWeighted(heatmap_normalized, 0.7, image, 0.3, 0)\n",
    "    \n",
    "    numer = weighted_image - np.min(weighted_image)\n",
    "    denom = (weighted_image.max() - weighted_image.min()) + 1e-8\n",
    "    final_image = numer / denom\n",
    "    final_image = (final_image * 255).astype(\"uint8\")\n",
    "\n",
    "    return final_image\n",
    "\n",
    "image = cv2.imread(root+'/man_bike.JPEG')\n",
    "image=cv2.resize(image,(256,256))\n",
    "image = np.asarray(image, np.float64)\n",
    "\n",
    "display=display_heatmap(heatmap,image)\n",
    "plt.matshow(display[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf9aa-2V4CKX"
   },
   "source": [
    "Show the heatmap for class ```'seashore, coast, seacoast, sea-coast'``` (```class_id = 978```), super-imposed onto the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RIX2_SHQjQa"
   },
   "source": [
    "### 2.4.3 Failure analysis using Grad-CAM [5 marks]\n",
    "\n",
    "Find an image (online, or from ImageNet or another dataset) which AlexNet classifies *incorrectly*. Display the image below, and show the model's predicted class. Then, generate the Grad-CAM heatmap and display it super-imposed onto the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "ptXj9TpFQjQa",
    "outputId": "264a6658-ad00-488b-dcda-467514626c59"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mammoth=Image.open(root+'/mammoth.jpg')\n",
    "\n",
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean, norm_std),\n",
    "    ])\n",
    "\n",
    "mammoth = data_transform(mammoth)\n",
    "mod = alexnet(pretrained=True)\n",
    "\n",
    "\n",
    "output = mod(mammoth.unsqueeze(0))\n",
    "\n",
    "_, pred_cls = output.max(dim=1, keepdim=True)\n",
    "print(pred_cls)\n",
    "percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100  \n",
    " \n",
    "\n",
    "heatmap = generate_heatmap(output, pred_cls, mod, mammoth.unsqueeze(0))\n",
    "mammoth=cv2.imread(root+'/mammoth.jpg')\n",
    "\n",
    "mammoth=cv2.resize(mammoth,(256,256))\n",
    "mammoth = np.asarray(mammoth, np.float64)\n",
    "show_result = display_heatmap(heatmap, mammoth)\n",
    "plt.matshow(show_result[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGoDmpH0QjQb"
   },
   "source": [
    "Briefly describe what explanation the Grad-CAM heatmap provides about why the model has failed to correctly classify your test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVAxygOtQjQb"
   },
   "source": [
    "The image that we have used is an mammoth image, but the model considers it as an ox. It may be because it has tusk similar to horns in an ox and also because of the fur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8nFMLuTQjQb"
   },
   "source": [
    "### 3 Overall quality [2 marks]\n",
    "\n",
    "Marks awarded for overall degree of code readibility and omission of unnecessary messy outupts (for example, please avoid printed losses for every batch of a long training process, large numpy arrays, etc.) throughout the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MlwXH8jQjQb"
   },
   "source": [
    "**Please refer to the submission section at the top of this notebook to prepare your submission.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZW-mCqFYQjQb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "COMP5623M_CW1_2022.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python395jvsc74a57bd03d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
